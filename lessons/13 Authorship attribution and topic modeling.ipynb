{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorship attribution of a text corpus\n",
    "=======================================\n",
    "\n",
    "Here we will repeat a famous experiment in authorship attribution, and try to discover who wrote the Federalist Papers!\n",
    "\n",
    "We have the corpus from our lesson on NLTK, and we have the `gensim` library that we used in our topic modeling experiments. We'll put these together to get what we need for authorship attribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data\n",
    "-------------------\n",
    "\n",
    "Now let's load up the Papers. They are in a folder called 'federalist' and each paper is numbered, e.g. 'federalist_7.txt'. We can just as easily do this using NLTK to make a corpus out of the folder, as we did last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of texts in corpus: ['federalist_1.txt', 'federalist_10.txt', 'federalist_11.txt', 'federalist_12.txt', 'federalist_13.txt', 'federalist_14.txt', 'federalist_15.txt', 'federalist_16.txt', 'federalist_17.txt', 'federalist_18.txt', 'federalist_19.txt', 'federalist_2.txt', 'federalist_20.txt', 'federalist_21.txt', 'federalist_22.txt', 'federalist_23.txt', 'federalist_24.txt', 'federalist_25.txt', 'federalist_26.txt', 'federalist_27.txt', 'federalist_28.txt', 'federalist_29.txt', 'federalist_3.txt', 'federalist_30.txt', 'federalist_31.txt', 'federalist_32.txt', 'federalist_33.txt', 'federalist_34.txt', 'federalist_35.txt', 'federalist_36.txt', 'federalist_37.txt', 'federalist_38.txt', 'federalist_39.txt', 'federalist_4.txt', 'federalist_40.txt', 'federalist_41.txt', 'federalist_42.txt', 'federalist_43.txt', 'federalist_44.txt', 'federalist_45.txt', 'federalist_46.txt', 'federalist_47.txt', 'federalist_48.txt', 'federalist_49.txt', 'federalist_5.txt', 'federalist_50.txt', 'federalist_51.txt', 'federalist_52.txt', 'federalist_53.txt', 'federalist_54.txt', 'federalist_55.txt', 'federalist_56.txt', 'federalist_57.txt', 'federalist_58.txt', 'federalist_59.txt', 'federalist_6.txt', 'federalist_60.txt', 'federalist_61.txt', 'federalist_62.txt', 'federalist_63.txt', 'federalist_64.txt', 'federalist_65.txt', 'federalist_66.txt', 'federalist_67.txt', 'federalist_68.txt', 'federalist_69.txt', 'federalist_7.txt', 'federalist_70.txt', 'federalist_71.txt', 'federalist_72.txt', 'federalist_73.txt', 'federalist_74.txt', 'federalist_75.txt', 'federalist_76.txt', 'federalist_77.txt', 'federalist_78.txt', 'federalist_79.txt', 'federalist_8.txt', 'federalist_80.txt', 'federalist_81.txt', 'federalist_82.txt', 'federalist_83.txt', 'federalist_84.txt', 'federalist_85.txt', 'federalist_9.txt']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.corpus.reader.util import read_regexp_block\n",
    "\n",
    "# Define how paragraphs look in our text files.\n",
    "def read_hanging_block( stream ):\n",
    "    return read_regexp_block( stream, \"^[A-Za-z]\" )\n",
    "\n",
    "corpus_root = '../textfiles/federalist'\n",
    "file_pattern = 'federalist_.*\\.txt'\n",
    "federalist = PlaintextCorpusReader( corpus_root, file_pattern, \n",
    "                                para_block_reader=read_hanging_block )\n",
    "print(\"List of texts in corpus:\", federalist.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorship attribution is done by comparing different *features* of the texts we are looking at. Examples include:\n",
    "\n",
    "* lexical features (average sentence length, variation in sentence length, range of words used)\n",
    "* punctuation features (average number of different marks per sentence)\n",
    "* word count features (e.g. frequency of the different common 'function words')\n",
    "* syntactic features (e.g. frequency of noun use, verb use, adjective use, etc.)\n",
    "\n",
    "Essentially there are a whole lot of approaches to take, and usually you want to take as many approaches as possible to arrive at some sort of consensus answer. Today we will try three approaches: looking at use of function words, at lexical diversity, and at relative frequency of parts of speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the word count feature - the frequency of \"function words\"\n",
    "------------------------------------------------------------------\n",
    "\n",
    "These are the words that we would normally leave out of any vocabulary analysis because they are so common - 'the', 'a', 'and', 'of', 'to', and so on. Indeed we left them out of our topic modeling trial last week for this very reason, but for authorship attribution, conversely, they might be very relevant! Let's retrieve them from NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : me : my : myself : we : our : ours : ourselves : you : your : yours : yourself : yourselves : he : him : his : himself : she : her : hers : herself : it : its : itself : they : them : their : theirs : themselves : what : which : who : whom : this : that : these : those : am : is : are : was : were : be : been : being : have : has : had : having : do : does : did : doing : a : an : the : and : but : if : or : because : as : until : while : of : at : by : for : with : about : against : between : into : through : during : before : after : above : below : to : from : up : down : in : out : on : off : over : under : again : further : then : once : here : there : when : where : why : how : all : any : both : each : few : more : most : other : some : such : no : nor : not : only : own : same : so : than : too : very : s : t : can : will : just : don : should : now : d : ll : m : o : re : ve : y : ain : aren : couldn : didn : doesn : hadn : hasn : haven : isn : ma : mightn : mustn : needn : shan : shouldn : wasn : weren : won : wouldn\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(\" : \".join(stopwords.words(\"english\")))\n",
    "print(len(stopwords.words(\"english\")))\n",
    "\n",
    "# Make the stopword list into a Python set. That will make our work much faster below.\n",
    "swset = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! Now we have, for each text, to count up the frequency of each of these words. This is called making a \"feature vector\" - each text will be reduced to a data structure that has a count for each of the function words.\n",
    "\n",
    "**PAY ATTENTION HERE!** This step, the conversion of text files to feature vectors, is where you will make or break any of these text analysis techniques. As we will see, when we are doing authorship attribution we want to count the stopwords, but when we do topic modeling we want to count everything *BUT* the stopwords! Think carefully about the theory and ideas behind what you are doing, when you use these tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 24,\n",
       " 'about': 106,\n",
       " 'above': 123,\n",
       " 'after': 55,\n",
       " 'again': 83,\n",
       " 'against': 45,\n",
       " 'all': 32,\n",
       " 'am': 51,\n",
       " 'an': 26,\n",
       " 'and': 8,\n",
       " 'any': 14,\n",
       " 'are': 43,\n",
       " 'as': 39,\n",
       " 'at': 48,\n",
       " 'be': 1,\n",
       " 'because': 72,\n",
       " 'been': 3,\n",
       " 'before': 41,\n",
       " 'being': 15,\n",
       " 'below': 110,\n",
       " 'between': 88,\n",
       " 'both': 89,\n",
       " 'but': 20,\n",
       " 'by': 11,\n",
       " 'can': 7,\n",
       " 'd': 122,\n",
       " 'did': 99,\n",
       " 'do': 50,\n",
       " 'does': 95,\n",
       " 'doing': 119,\n",
       " 'down': 112,\n",
       " 'during': 111,\n",
       " 'each': 81,\n",
       " 'few': 78,\n",
       " 'for': 12,\n",
       " 'from': 37,\n",
       " 'further': 63,\n",
       " 'had': 17,\n",
       " 'has': 54,\n",
       " 'have': 57,\n",
       " 'having': 6,\n",
       " 'he': 74,\n",
       " 'her': 96,\n",
       " 'here': 94,\n",
       " 'hers': 124,\n",
       " 'herself': 100,\n",
       " 'him': 91,\n",
       " 'himself': 79,\n",
       " 'his': 92,\n",
       " 'how': 107,\n",
       " 'i': 31,\n",
       " 'if': 9,\n",
       " 'in': 59,\n",
       " 'into': 42,\n",
       " 'is': 28,\n",
       " 'it': 33,\n",
       " 'its': 29,\n",
       " 'itself': 76,\n",
       " 'just': 18,\n",
       " 'me': 75,\n",
       " 'more': 13,\n",
       " 'most': 62,\n",
       " 'my': 44,\n",
       " 'myself': 116,\n",
       " 'no': 47,\n",
       " 'nor': 85,\n",
       " 'not': 40,\n",
       " 'now': 98,\n",
       " 'of': 52,\n",
       " 'off': 114,\n",
       " 'on': 10,\n",
       " 'once': 105,\n",
       " 'only': 93,\n",
       " 'or': 35,\n",
       " 'other': 70,\n",
       " 'our': 64,\n",
       " 'ours': 115,\n",
       " 'ourselves': 97,\n",
       " 'out': 108,\n",
       " 'over': 65,\n",
       " 'own': 0,\n",
       " 're': 121,\n",
       " 's': 117,\n",
       " 'same': 60,\n",
       " 'she': 102,\n",
       " 'should': 38,\n",
       " 'so': 46,\n",
       " 'some': 84,\n",
       " 'such': 27,\n",
       " 't': 126,\n",
       " 'than': 49,\n",
       " 'that': 25,\n",
       " 'the': 58,\n",
       " 'their': 21,\n",
       " 'theirs': 104,\n",
       " 'them': 56,\n",
       " 'themselves': 16,\n",
       " 'then': 82,\n",
       " 'there': 71,\n",
       " 'these': 67,\n",
       " 'they': 53,\n",
       " 'this': 19,\n",
       " 'those': 36,\n",
       " 'through': 87,\n",
       " 'to': 2,\n",
       " 'too': 69,\n",
       " 'under': 34,\n",
       " 'until': 120,\n",
       " 'up': 77,\n",
       " 'very': 101,\n",
       " 'was': 86,\n",
       " 'we': 61,\n",
       " 'were': 68,\n",
       " 'what': 90,\n",
       " 'when': 73,\n",
       " 'where': 80,\n",
       " 'which': 30,\n",
       " 'while': 113,\n",
       " 'who': 5,\n",
       " 'whom': 103,\n",
       " 'why': 109,\n",
       " 'will': 22,\n",
       " 'with': 4,\n",
       " 'won': 118,\n",
       " 'you': 23,\n",
       " 'your': 66,\n",
       " 'yourselves': 125}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Make a 2D array of each text reduced to its sequence in stopwords\n",
    "stopword_texts = [[w.lower() for w in federalist.words(paper) \n",
    "                   if w.lower() in swset] \n",
    "                  for paper in federalist.fileids()]\n",
    "\n",
    "# Now make a feature vector set - a gensim corpus - from these texts.\n",
    "swdictionary = corpora.Dictionary(stopword_texts)\n",
    "swdictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have our \"texts\", which are lists of stopwords, and we have our dictionary, which assigns a unique ID to each word. We put these things together to make a vector of each text, which will be a series of `(dictionaryID, count)` tuples. Anytime the count is zero, the dictionary ID will simply be left out of that text's vector. We will use the `doc2bow` method to do this; the result looks something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4),\n",
       " (1, 34),\n",
       " (2, 71),\n",
       " (3, 3),\n",
       " (4, 6),\n",
       " (5, 8),\n",
       " (6, 1),\n",
       " (7, 3),\n",
       " (8, 40),\n",
       " (9, 4),\n",
       " (10, 9),\n",
       " (11, 14),\n",
       " (12, 12),\n",
       " (13, 7),\n",
       " (14, 6),\n",
       " (15, 1),\n",
       " (16, 2),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 14),\n",
       " (20, 2),\n",
       " (21, 13),\n",
       " (22, 25),\n",
       " (23, 7),\n",
       " (24, 25),\n",
       " (25, 28),\n",
       " (26, 11),\n",
       " (27, 1),\n",
       " (28, 12),\n",
       " (29, 10),\n",
       " (30, 18),\n",
       " (31, 14),\n",
       " (32, 9),\n",
       " (33, 20),\n",
       " (34, 3),\n",
       " (35, 6),\n",
       " (36, 9),\n",
       " (37, 11),\n",
       " (38, 1),\n",
       " (39, 10),\n",
       " (40, 14),\n",
       " (41, 1),\n",
       " (42, 2),\n",
       " (43, 12),\n",
       " (44, 8),\n",
       " (45, 1),\n",
       " (46, 3),\n",
       " (47, 3),\n",
       " (48, 8),\n",
       " (49, 11),\n",
       " (50, 1),\n",
       " (51, 3),\n",
       " (52, 105),\n",
       " (53, 6),\n",
       " (54, 6),\n",
       " (55, 2),\n",
       " (56, 2),\n",
       " (57, 10),\n",
       " (58, 129),\n",
       " (59, 26),\n",
       " (60, 1),\n",
       " (61, 8),\n",
       " (62, 2),\n",
       " (63, 1),\n",
       " (64, 3),\n",
       " (65, 1),\n",
       " (66, 10),\n",
       " (67, 3),\n",
       " (68, 1),\n",
       " (69, 3),\n",
       " (70, 3),\n",
       " (71, 2),\n",
       " (72, 1),\n",
       " (73, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swdictionary.doc2bow(stopword_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was the first text, and now we want this sort of \"bag of words\" (bow) for all of the texts! We use a list comprehension again to get that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_corpus = [swdictionary.doc2bow(text) \n",
    "                   for text in stopword_texts]\n",
    "len(stopword_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something similar to get the distribution of parts of speech. We will POS-tag all the texts, choose the twenty most common parts of speech throughout the corpus excluding punctuation, and then make a similar vector for each text counting the instances of each part of speech.\n",
    "\n",
    "Here is how to tag a single text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('People', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('State', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('New', 'NNP'),\n",
       " ('York', 'NNP'),\n",
       " (':', ':'),\n",
       " ('AFTER', 'NNP'),\n",
       " ('an', 'DT'),\n",
       " ('unequivocal', 'JJ'),\n",
       " ('experience', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('inefficiency', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('subsisting', 'VBG'),\n",
       " ('federal', 'JJ'),\n",
       " ('government', 'NN'),\n",
       " (',', ','),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('called', 'VBN'),\n",
       " ('upon', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('deliberate', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('Constitution', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('United', 'NNP'),\n",
       " ('States', 'NNPS'),\n",
       " ('of', 'IN'),\n",
       " ('America', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('subject', 'JJ'),\n",
       " ('speaks', 'VBZ'),\n",
       " ('its', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('importance', 'NN'),\n",
       " (';', ':'),\n",
       " ('comprehending', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('consequences', 'NNS'),\n",
       " ('nothing', 'NN'),\n",
       " ('less', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('existence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('UNION', 'NNP'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('safety', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('welfare', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('parts', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('composed', 'VBN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('fate', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('empire', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('respects', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('interesting', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('frequently', 'RB'),\n",
       " ('remarked', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('seems', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('been', 'VBN'),\n",
       " ('reserved', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('country', 'NN'),\n",
       " (',', ','),\n",
       " ('by', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('conduct', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('example', 'NN'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('decide', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('important', 'JJ'),\n",
       " ('question', 'NN'),\n",
       " (',', ','),\n",
       " ('whether', 'IN'),\n",
       " ('societies', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('men', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('really', 'RB'),\n",
       " ('capable', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('not', 'RB'),\n",
       " ('of', 'IN'),\n",
       " ('establishing', 'VBG'),\n",
       " ('good', 'JJ'),\n",
       " ('government', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('reflection', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('choice', 'NN'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('whether', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('forever', 'RB'),\n",
       " ('destined', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('depend', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('political', 'JJ'),\n",
       " ('constitutions', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('accident', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('force', 'NN'),\n",
       " ('.', '.'),\n",
       " ('If', 'IN'),\n",
       " ('there', 'EX'),\n",
       " ('be', 'VB'),\n",
       " ('any', 'DT'),\n",
       " ('truth', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('remark', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('crisis', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('arrived', 'VBN'),\n",
       " ('may', 'MD'),\n",
       " ('with', 'IN'),\n",
       " ('propriety', 'NN'),\n",
       " ('be', 'VB'),\n",
       " ('regarded', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('era', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('which', 'WDT'),\n",
       " ('that', 'DT'),\n",
       " ('decision', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('made', 'VBN'),\n",
       " (';', ':'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('wrong', 'JJ'),\n",
       " ('election', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('part', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('shall', 'MD'),\n",
       " ('act', 'VB'),\n",
       " ('may', 'MD'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('view', 'NN'),\n",
       " (',', ','),\n",
       " ('deserve', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('considered', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('general', 'JJ'),\n",
       " ('misfortune', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mankind', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('idea', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('add', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('inducements', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('philanthropy', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('those', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('patriotism', 'NN'),\n",
       " (',', ','),\n",
       " ('to', 'TO'),\n",
       " ('heighten', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('solicitude', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('all', 'DT'),\n",
       " ('considerate', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('good', 'JJ'),\n",
       " ('men', 'NNS'),\n",
       " ('must', 'MD'),\n",
       " ('feel', 'VB'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Happy', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('it', 'PRP'),\n",
       " ('be', 'VB'),\n",
       " ('if', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('choice', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('directed', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('judicious', 'JJ'),\n",
       " ('estimate', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('true', 'JJ'),\n",
       " ('interests', 'NNS'),\n",
       " (',', ','),\n",
       " ('unperplexed', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('unbiased', 'JJ'),\n",
       " ('by', 'IN'),\n",
       " ('considerations', 'NNS'),\n",
       " ('not', 'RB'),\n",
       " ('connected', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('public', 'JJ'),\n",
       " ('good', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('But', 'CC'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('thing', 'NN'),\n",
       " ('more', 'RBR'),\n",
       " ('ardently', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('wished', 'VBN'),\n",
       " ('than', 'IN'),\n",
       " ('seriously', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('expected', 'VBN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('plan', 'NN'),\n",
       " ('offered', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('our', 'PRP$'),\n",
       " ('deliberations', 'NNS'),\n",
       " ('affects', 'VBZ'),\n",
       " ('too', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('particular', 'JJ'),\n",
       " ('interests', 'NNS'),\n",
       " (',', ','),\n",
       " ('innovates', 'VBZ'),\n",
       " ('upon', 'IN'),\n",
       " ('too', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('local', 'JJ'),\n",
       " ('institutions', 'NNS'),\n",
       " (',', ','),\n",
       " ('not', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('involve', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('discussion', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('variety', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('objects', 'NNS'),\n",
       " ('foreign', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('its', 'PRP$'),\n",
       " ('merits', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('of', 'IN'),\n",
       " ('views', 'NNS'),\n",
       " (',', ','),\n",
       " ('passions', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('prejudices', 'NNS'),\n",
       " ('little', 'RB'),\n",
       " ('favorable', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('discovery', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('truth', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Among', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('formidable', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('obstacles', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('the', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('Constitution', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('encounter', 'VB'),\n",
       " ('may', 'MD'),\n",
       " ('readily', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('distinguished', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('obvious', 'JJ'),\n",
       " ('interest', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('certain', 'JJ'),\n",
       " ('class', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('men', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('State', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('resist', 'VB'),\n",
       " ('all', 'DT'),\n",
       " ('changes', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('may', 'MD'),\n",
       " ('hazard', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('diminution', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('power', 'NN'),\n",
       " (',', ','),\n",
       " ('emolument', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('consequence', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('offices', 'NNS'),\n",
       " ('they', 'PRP'),\n",
       " ('hold', 'VBP'),\n",
       " ('under', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('State', 'NNP'),\n",
       " ('establishments', 'NNS'),\n",
       " (';', ':'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('perverted', 'JJ'),\n",
       " ('ambition', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('another', 'DT'),\n",
       " ('class', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('men', 'NNS'),\n",
       " (',', ','),\n",
       " ('who', 'WP'),\n",
       " ('will', 'MD'),\n",
       " ('either', 'CC'),\n",
       " ('hope', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('aggrandize', 'VB'),\n",
       " ('themselves', 'PRP'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('confusions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('country', 'NN'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('will', 'MD'),\n",
       " ('flatter', 'VB'),\n",
       " ('themselves', 'PRP'),\n",
       " ('with', 'IN'),\n",
       " ('fairer', 'JJ'),\n",
       " ('prospects', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('elevation', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('subdivision', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('empire', 'NN'),\n",
       " ('into', 'IN'),\n",
       " ('several', 'JJ'),\n",
       " ('partial', 'JJ'),\n",
       " ('confederacies', 'NNS'),\n",
       " ('than', 'IN'),\n",
       " ('from', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('union', 'NN'),\n",
       " ('under', 'IN'),\n",
       " ('one', 'CD'),\n",
       " ('government', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " (',', ','),\n",
       " ('however', 'RB'),\n",
       " (',', ','),\n",
       " ('my', 'PRP$'),\n",
       " ('design', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('dwell', 'VB'),\n",
       " ('upon', 'IN'),\n",
       " ('observations', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('nature', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('well', 'RB'),\n",
       " ('aware', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('disingenuous', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('resolve', 'VB'),\n",
       " ('indiscriminately', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('opposition', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('set', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('men', 'NNS'),\n",
       " ('(', '('),\n",
       " ('merely', 'RB'),\n",
       " ('because', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('situations', 'NNS'),\n",
       " ('might', 'MD'),\n",
       " ('subject', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('suspicion', 'NN'),\n",
       " (')', ')'),\n",
       " ('into', 'IN'),\n",
       " ('interested', 'JJ'),\n",
       " ('or', 'CC'),\n",
       " ('ambitious', 'JJ'),\n",
       " ('views', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Candor', 'NNP'),\n",
       " ('will', 'MD'),\n",
       " ('oblige', 'VB'),\n",
       " ('us', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('admit', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('even', 'RB'),\n",
       " ('such', 'JJ'),\n",
       " ('men', 'NNS'),\n",
       " ('may', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('actuated', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('upright', 'JJ'),\n",
       " ('intentions', 'NNS'),\n",
       " (';', ':'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('cannot', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('doubted', 'VBN'),\n",
       " ('that', 'IN'),\n",
       " ('much', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('opposition', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('has', 'VBZ'),\n",
       " ('made', 'VBN'),\n",
       " ('its', 'PRP$'),\n",
       " ('appearance', 'NN'),\n",
       " (',', ','),\n",
       " ('or', 'CC'),\n",
       " ('may', 'MD'),\n",
       " ('hereafter', 'VB'),\n",
       " ('make', 'VB'),\n",
       " ('its', 'PRP$'),\n",
       " ('appearance', 'NN'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('spring', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('sources', 'NNS'),\n",
       " (',', ','),\n",
       " ('blameless', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('least', 'JJS'),\n",
       " (',', ','),\n",
       " ('if', 'IN'),\n",
       " ('not', 'RB'),\n",
       " ('respectable', 'JJ'),\n",
       " ('--', ':'),\n",
       " ('the', 'DT'),\n",
       " ('honest', 'JJS'),\n",
       " ('errors', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('minds', 'NNS'),\n",
       " ('led', 'VBN'),\n",
       " ('astray', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('preconceived', 'JJ'),\n",
       " ('jealousies', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('fears', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('So', 'RB'),\n",
       " ('numerous', 'JJ'),\n",
       " ('indeed', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('so', 'RB'),\n",
       " ('powerful', 'JJ'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('causes', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('serve', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('give', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('false', 'JJ'),\n",
       " ('bias', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('judgment', 'NN'),\n",
       " (',', ','),\n",
       " ('that', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " (',', ','),\n",
       " ('upon', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('occasions', 'NNS'),\n",
       " (',', ','),\n",
       " ('see', 'VBP'),\n",
       " ('wise', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('good', 'JJ'),\n",
       " ('men', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('wrong', 'JJ'),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('questions', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('magnitude', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('society', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('circumstance', 'NN'),\n",
       " (',', ','),\n",
       " ('if', 'IN'),\n",
       " ('duly', 'RB'),\n",
       " ('attended', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " (',', ','),\n",
       " ('would', 'MD'),\n",
       " ('furnish', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('lesson', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('moderation', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('those', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('ever', 'RB'),\n",
       " ('so', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('persuaded', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('being', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('controversy', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('further', 'JJ'),\n",
       " ('reason', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('caution', 'NN'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('respect', 'NN'),\n",
       " (',', ','),\n",
       " ('might', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('drawn', 'VBN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('reflection', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('always', 'RB'),\n",
       " ('sure', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('advocate', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('truth', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('influenced', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('purer', 'NN'),\n",
       " ('principles', 'NNS'),\n",
       " ('than', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('antagonists', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('Ambition', 'NNP'),\n",
       " (',', ','),\n",
       " ('avarice', 'NN'),\n",
       " (',', ','),\n",
       " ('personal', 'JJ'),\n",
       " ('animosity', 'NN'),\n",
       " (',', ','),\n",
       " ('party', 'NN'),\n",
       " ('opposition', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('many', 'JJ'),\n",
       " ('other', 'JJ'),\n",
       " ('motives', 'NNS'),\n",
       " ('not', 'RB'),\n",
       " ('more', 'RBR'),\n",
       " ('laudable', 'JJ'),\n",
       " ('than', 'IN'),\n",
       " ('these', 'DT'),\n",
       " (',', ','),\n",
       " ('are', 'VBP'),\n",
       " ('apt', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('operate', 'VB'),\n",
       " ('as', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('upon', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('support', 'VBP'),\n",
       " ('as', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('who', 'WP'),\n",
       " ('oppose', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'JJ'),\n",
       " ('side', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('question', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Were', 'WRB'),\n",
       " ('there', 'EX'),\n",
       " ('not', 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('these', 'DT'),\n",
       " ('inducements', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('moderation', 'NN'),\n",
       " (',', ','),\n",
       " ('nothing', 'NN'),\n",
       " ('could', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('more', 'JJR'),\n",
       " ('ill', 'JJ'),\n",
       " ('-', ':'),\n",
       " ('judged', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('intolerant', 'JJ'),\n",
       " ('spirit', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('has', 'VBZ'),\n",
       " (',', ','),\n",
       " ('at', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('times', 'NNS'),\n",
       " (',', ','),\n",
       " ('characterized', 'VBD'),\n",
       " ('political', 'JJ'),\n",
       " ('parties', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('For', 'IN'),\n",
       " ('in', 'IN'),\n",
       " ('politics', 'NNS'),\n",
       " (',', ','),\n",
       " ('as', 'IN'),\n",
       " ('in', 'IN'),\n",
       " ('religion', 'NN'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('equally', 'RB'),\n",
       " ('absurd', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('aim', 'VB'),\n",
       " ('at', 'IN'),\n",
       " ('making', 'VBG'),\n",
       " ('proselytes', 'NNS'),\n",
       " ('by', 'IN'),\n",
       " ('fire', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('sword', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Heresies', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('either', 'CC'),\n",
       " ('can', 'MD'),\n",
       " ('rarely', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('cured', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('persecution', 'NN'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('yet', 'RB'),\n",
       " (',', ','),\n",
       " ('however', 'RB'),\n",
       " ('just', 'RB'),\n",
       " ('these', 'DT'),\n",
       " ('sentiments', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('allowed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('already', 'RB'),\n",
       " ('sufficient', 'JJ'),\n",
       " ('indications', 'NNS'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('happen', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('as', 'IN'),\n",
       " ('in', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('former', 'JJ'),\n",
       " ('cases', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('great', 'JJ'),\n",
       " ('national', 'JJ'),\n",
       " ('discussion', 'NN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DT'),\n",
       " ('torrent', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('angry', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('malignant', 'JJ'),\n",
       " ('passions', 'NNS'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('let', 'VBN'),\n",
       " ('loose', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('To', 'TO'),\n",
       " ('judge', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('conduct', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('opposite', 'JJ'),\n",
       " ('parties', 'NNS'),\n",
       " (',', ','),\n",
       " ('we', 'PRP'),\n",
       " ('shall', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('led', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('conclude', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('mutually', 'RB'),\n",
       " ('hope', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('evince', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('justness', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('opinions', 'NNS'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('to', 'TO'),\n",
       " ('increase', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('number', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('converts', 'NNS'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('loudness', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('declamations', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('bitterness', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('invectives', 'NNS'),\n",
       " ('.', '.'),\n",
       " ('An', 'DT'),\n",
       " ('enlightened', 'JJ'),\n",
       " ('zeal', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('energy', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('efficiency', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('government', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('stigmatized', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('offspring', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('temper', 'JJ'),\n",
       " ('fond', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('despotic', 'JJ'),\n",
       " ('power', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('hostile', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('principles', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('liberty', 'NN'),\n",
       " ('.', '.'),\n",
       " ('An', 'DT'),\n",
       " ('over', 'IN'),\n",
       " ('-', ':'),\n",
       " ('scrupulous', 'JJ'),\n",
       " ('jealousy', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('danger', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('rights', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " (',', ','),\n",
       " ('which', 'WDT'),\n",
       " ('is', 'VBZ'),\n",
       " ('more', 'RBR'),\n",
       " ('commonly', 'RB'),\n",
       " ('the', 'DT'),\n",
       " ('fault', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('head', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('heart', 'NN'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('represented', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('mere', 'JJ'),\n",
       " ('pretense', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('artifice', 'NN'),\n",
       " (',', ','),\n",
       " ('the', 'DT'),\n",
       " ('stale', 'JJ'),\n",
       " ('bait', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('popularity', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('expense', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('public', 'JJ'),\n",
       " ('good', 'NN'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('forgotten', 'VBN'),\n",
       " (',', ','),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('one', 'CD'),\n",
       " ('hand', 'NN'),\n",
       " (',', ','),\n",
       " ('that', 'IN'),\n",
       " ('jealousy', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('usual', 'JJ'),\n",
       " ('concomitant', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('love', 'NN'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('noble', 'JJ'),\n",
       " ('enthusiasm', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('liberty', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('apt', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('infected', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "pos_tag(federalist.words('federalist_1.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...so let's do this for all the texts, and put the resulting arrays into an outer array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TO',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ':',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " ',',\n",
       " 'IN',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ':',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'DT',\n",
       " ',',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NN',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'CC',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'TO',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'VBZ',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " ',',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'VBP',\n",
       " 'RBR',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " '.',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'VBZ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'TO',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNPS',\n",
       " '.',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NNPS',\n",
       " ',',\n",
       " 'TO',\n",
       " 'WP$',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " ',',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'VBG',\n",
       " 'RBR',\n",
       " 'JJ',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " ',',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNPS',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'CD',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'RBS',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'DT',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ':',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'VBN',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'WDT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " ':',\n",
       " 'CC',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'CD',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'RBS',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'PRP$',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'IN',\n",
       " ',',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'PRP',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'RB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " ',',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJR',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'WDT',\n",
       " 'VBD',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " '.',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " ',',\n",
       " 'PRP',\n",
       " 'VBD',\n",
       " 'RBR',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'WDT',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'RBS',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'IN',\n",
       " 'WDT',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RBR',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " '.',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'WDT',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'JJS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'WRB',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'PRP$',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'IN',\n",
       " 'WP',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'DT',\n",
       " 'JJS',\n",
       " 'NN',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'VBG',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNPS',\n",
       " ',',\n",
       " 'VBP',\n",
       " ',',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'VBD',\n",
       " 'PRP',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'CC',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'NNS',\n",
       " ',',\n",
       " 'IN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBZ',\n",
       " ',',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NNP',\n",
       " 'NN',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'CC',\n",
       " 'NNS',\n",
       " '.',\n",
       " 'EX',\n",
       " 'VBP',\n",
       " 'JJ',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " ',',\n",
       " 'IN',\n",
       " 'WDT',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'RB',\n",
       " 'JJS',\n",
       " '.',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'WDT',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " 'VBN',\n",
       " ',',\n",
       " 'VBZ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'VBG',\n",
       " 'NNS',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " ',',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'VBN',\n",
       " 'WRB',\n",
       " 'RB',\n",
       " 'PRP',\n",
       " 'VBZ',\n",
       " 'VBN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " ':',\n",
       " 'IN',\n",
       " 'TO',\n",
       " 'VBG',\n",
       " 'NNS',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " 'CC',\n",
       " 'RB',\n",
       " '.',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'VBN',\n",
       " '.',\n",
       " 'WRB',\n",
       " 'NNS',\n",
       " 'VBP',\n",
       " 'RB',\n",
       " 'VBN',\n",
       " 'WP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " '``',\n",
       " 'VBG',\n",
       " 'PRP',\n",
       " 'RP',\n",
       " 'RB',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NNP',\n",
       " '.',\n",
       " 'WP',\n",
       " 'NN',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'JJ',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'VB',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'CC',\n",
       " 'MD',\n",
       " 'PRP',\n",
       " 'VBP',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'RB',\n",
       " 'RB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'WDT',\n",
       " 'VBD',\n",
       " 'PRP$',\n",
       " 'VBG',\n",
       " 'VBN',\n",
       " 'VBZ',\n",
       " '.',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'PRP',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'RP',\n",
       " 'JJ',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " 'NNP',\n",
       " ',',\n",
       " 'IN',\n",
       " 'VBG',\n",
       " 'CC',\n",
       " 'VBG',\n",
       " 'NN',\n",
       " ',',\n",
       " 'WDT',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'RB',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " ',',\n",
       " 'CC',\n",
       " 'TO',\n",
       " 'VB',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'NN',\n",
       " '.',\n",
       " 'WP',\n",
       " 'MD',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " 'IN',\n",
       " 'DT',\n",
       " 'NN',\n",
       " '.',\n",
       " 'DT',\n",
       " 'MD',\n",
       " 'RB',\n",
       " 'VB',\n",
       " 'VBN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'JJ',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sequences of words into sequences of part-of-speech tags\n",
    "pos_texts = []\n",
    "for paper in federalist.fileids():\n",
    "    tagged = pos_tag(federalist.words(paper))\n",
    "    tagsonly = [x[1] for x in tagged]\n",
    "    pos_texts.append(tagsonly)\n",
    "    \n",
    "pos_texts[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, just as before, make a dictionary out of these \"texts\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': 41,\n",
       " \"''\": 39,\n",
       " '(': 19,\n",
       " ')': 2,\n",
       " ',': 16,\n",
       " '.': 27,\n",
       " ':': 18,\n",
       " 'CC': 13,\n",
       " 'CD': 34,\n",
       " 'DT': 29,\n",
       " 'EX': 25,\n",
       " 'FW': 42,\n",
       " 'IN': 10,\n",
       " 'JJ': 3,\n",
       " 'JJR': 7,\n",
       " 'JJS': 28,\n",
       " 'MD': 12,\n",
       " 'NN': 5,\n",
       " 'NNP': 17,\n",
       " 'NNPS': 9,\n",
       " 'NNS': 22,\n",
       " 'PDT': 32,\n",
       " 'POS': 40,\n",
       " 'PRP': 24,\n",
       " 'PRP$': 6,\n",
       " 'RB': 26,\n",
       " 'RBR': 4,\n",
       " 'RBS': 33,\n",
       " 'RP': 36,\n",
       " 'SYM': 37,\n",
       " 'TO': 11,\n",
       " 'UH': 23,\n",
       " 'VB': 1,\n",
       " 'VBD': 21,\n",
       " 'VBG': 30,\n",
       " 'VBN': 0,\n",
       " 'VBP': 31,\n",
       " 'VBZ': 15,\n",
       " 'WDT': 8,\n",
       " 'WP': 14,\n",
       " 'WP$': 35,\n",
       " 'WRB': 20,\n",
       " '``': 38}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posdict = corpora.Dictionary(pos_texts)\n",
    "posdict.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, let's filter out the punctuation, and limit ourselves to the top 15 parts of speech. We can filter the dictionary like this. First let's see what the list of items looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'VBN'),\n",
       " (1, 'VB'),\n",
       " (35, 'WP$'),\n",
       " (2, ')'),\n",
       " (3, 'JJ'),\n",
       " (28, 'JJS'),\n",
       " (5, 'NN'),\n",
       " (6, 'PRP$'),\n",
       " (7, 'JJR'),\n",
       " (8, 'WDT'),\n",
       " (40, 'POS'),\n",
       " (38, '``'),\n",
       " (9, 'NNPS'),\n",
       " (10, 'IN'),\n",
       " (11, 'TO'),\n",
       " (12, 'MD'),\n",
       " (13, 'CC'),\n",
       " (14, 'WP'),\n",
       " (15, 'VBZ'),\n",
       " (42, 'FW'),\n",
       " (16, ','),\n",
       " (18, ':'),\n",
       " (19, '('),\n",
       " (20, 'WRB'),\n",
       " (21, 'VBD'),\n",
       " (41, '$'),\n",
       " (22, 'NNS'),\n",
       " (39, \"''\"),\n",
       " (23, 'UH'),\n",
       " (32, 'PDT'),\n",
       " (37, 'SYM'),\n",
       " (24, 'PRP'),\n",
       " (25, 'EX'),\n",
       " (26, 'RB'),\n",
       " (27, '.'),\n",
       " (4, 'RBR'),\n",
       " (29, 'DT'),\n",
       " (30, 'VBG'),\n",
       " (31, 'VBP'),\n",
       " (36, 'RP'),\n",
       " (17, 'NNP'),\n",
       " (33, 'RBS'),\n",
       " (34, 'CD')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in posdict.iteritems()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then let's make a note of the IDs of the punctuation ones..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 2, 6, 38, 16, 18, 19, 41, 39, 27]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_ids = [x[0] for x in posdict.iteritems() if not x[1].isalpha()]\n",
    "punct_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and finally use this list in our filtering logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CC': 12,\n",
       " 'DT': 7,\n",
       " 'IN': 9,\n",
       " 'JJ': 3,\n",
       " 'MD': 11,\n",
       " 'NN': 5,\n",
       " 'NNS': 4,\n",
       " 'PRP': 14,\n",
       " 'RB': 6,\n",
       " 'TO': 10,\n",
       " 'VB': 1,\n",
       " 'VBD': 2,\n",
       " 'VBN': 0,\n",
       " 'VBZ': 13,\n",
       " 'WDT': 8}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posdict.filter_tokens(bad_ids=punct_ids)\n",
    "posdict.filter_extremes(no_above=1, keep_n=15)\n",
    "posdict.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! We have our dictionary the way we want it, so we can make a second gensim corpus out of our texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 68),\n",
       " (1, 125),\n",
       " (2, 22),\n",
       " (3, 170),\n",
       " (4, 111),\n",
       " (5, 298),\n",
       " (6, 75),\n",
       " (7, 278),\n",
       " (8, 20),\n",
       " (9, 320),\n",
       " (10, 90),\n",
       " (11, 68),\n",
       " (12, 67),\n",
       " (13, 32),\n",
       " (14, 56)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_corpus = [posdict.doc2bow(text) for text in pos_texts]\n",
    "pos_corpus[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have made two corpora from our texts; one represents the frequency of function words, and the other represents the frequency of common parts of speech.\n",
    "\n",
    "But now we will want to normalize our vectors a little bit - some texts are a lot longer than others, so will have many more function words overall, and we don't want this fact to affect our results. So we need to scale the values in each tuple, keeping them in proportion with each other but always between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.2125),\n",
       " (1, 0.390625),\n",
       " (2, 0.06875),\n",
       " (3, 0.53125),\n",
       " (4, 0.346875),\n",
       " (5, 0.93125),\n",
       " (6, 0.234375),\n",
       " (7, 0.86875),\n",
       " (8, 0.0625),\n",
       " (9, 1.0),\n",
       " (10, 0.28125),\n",
       " (11, 0.2125),\n",
       " (12, 0.209375),\n",
       " (13, 0.1),\n",
       " (14, 0.175)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scale(vector):\n",
    "    size = 0.0\n",
    "    maximum = 0.0\n",
    "    for t in vector:\n",
    "        size += t[1]\n",
    "        if t[1] > maximum:\n",
    "            maximum = t[1]\n",
    "    scaled = []\n",
    "    for t in vector:\n",
    "        fpcount = float(t[1])\n",
    "        factor = size / size * maximum\n",
    "        scaled.append((t[0], fpcount / factor))\n",
    "    return scaled\n",
    "\n",
    "stopword_corpus = [scale(v) for v in stopword_corpus]\n",
    "pos_corpus = [scale(v) for v in pos_corpus]\n",
    "pos_corpus[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the results\n",
    "-------------------\n",
    "Okay! We have a set of criteria - the frequency of our function words - and a corresponding set of values for each text. It's time to crunch the numbers and see which papers resemble each other.\n",
    "\n",
    "We know that there were three authors, so we want to see if we can make the 85 different papers cluster into three groups. There is a statistical function for this called KMeans, from the \"scikit-learn\" module which has a lot of things for machine learning. (Dividing data into clusters of similar things is a pretty common thing to have to do in machine learning. Lucky for us.)\n",
    "\n",
    "First we define a function to do the clustering for each data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def PredictAuthors(fvs):\n",
    "    km = KMeans(n_clusters=3)\n",
    "    km.fit(fvs)\n",
    "    return km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this, we need to convert our gensim corpus into a matrix that SciPy recognizes. Gensim gives us a utility to do this. In order to get our matrix the right way around, we will also have to transpose it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<85x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1275 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import transpose\n",
    "from gensim.matutils import corpus2csc\n",
    "\n",
    "stopword_matrix = transpose(corpus2csc(stopword_corpus))\n",
    "pos_matrix = transpose(corpus2csc(pos_corpus))\n",
    "pos_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we run this on our data table of the function word frequencies and get a complicated result. We ask for the labels of that result and get something that looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 0 2 0 0 2 2 2 1 2 0 0 2 0 0 0 2 2 0 1 0 0 2 2 0 0 0 0 0 2 1 2 2 2\n",
      " 2 2 2 2 2 2 2 1 2 2 2 2 2 0 0 2 2 0 0 0 0 0 2 1 2 2 2 0 2 0 0 2 0 0 0 0 0\n",
      " 0 2 0 0 2 0 2 0 0 0 0]\n",
      "[1 0 1 0 1 0 0 1 0 0 0 2 0 0 0 1 1 1 1 1 1 1 2 1 1 1 1 1 0 1 0 1 0 2 1 0 0\n",
      " 1 0 0 0 0 0 0 2 0 0 0 0 1 1 0 0 0 1 0 1 1 0 0 2 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "stopword_result = PredictAuthors( stopword_matrix ).labels_ \n",
    "print(stopword_result)\n",
    "pos_result = PredictAuthors( pos_matrix ).labels_ \n",
    "print(pos_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these numbers (0, 1, 2) represents an author. We know that Hamilton was responsible for most of the papers, Madison for most of the rest, and Jay for the fewest. So let's assign the authors on that assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 42), (2, 38), (1, 5)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Hamilton', 1: 'Jay', 2: 'Madison'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "author_order = [\"Hamilton\", \"Madison\", \"Jay\"]\n",
    "\n",
    "freq_order = FreqDist(stopword_result).most_common(3)\n",
    "print(freq_order)\n",
    "\n",
    "mapping = {}\n",
    "for i in range(3):\n",
    "    mapping[freq_order[i][0]] = author_order[i]\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put this into a function definition, since we'll have to do it twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Jay',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Jay',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Jay',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Jay',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Jay',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Madison',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton',\n",
       " 'Hamilton']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assign_author(result):\n",
    "    author_order = [\"Hamilton\", \"Madison\", \"Jay\"]\n",
    "    freq_order = FreqDist(result).most_common(3)\n",
    "    mapping = {}\n",
    "    for i in range(3):\n",
    "        mapping[freq_order[i][0]] = author_order[i]\n",
    "        \n",
    "    return [mapping.get(x) for x in result]\n",
    "\n",
    "assign_author(stopword_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how did that do against reality? Let's read in the real answers and add them to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hamilton', 'Jay', 'Jay', 'Jay', 'Jay', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Madison', 'Hamilton', 'Hamilton', 'Hamilton', 'Madison', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton and Madison', 'Hamilton and Madison', 'Hamilton and Madison', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Hamilton or Madison', 'Madison', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton or Madison', 'Hamilton or Madison', 'Jay', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton', 'Hamilton']\n"
     ]
    }
   ],
   "source": [
    "ff = open( \"../textfiles/federalist/metadata.txt\" )\n",
    "real_author = []\n",
    "for line in ff:\n",
    "    data = line.split()\n",
    "    our_author = data[1].title()\n",
    "    if data[2] == 'AND' or data[2] == 'OR':\n",
    "        our_author = \" \".join( [ our_author, data[2].lower(), \n",
    "                                data[3].title() ] )\n",
    "    real_author.append( our_author )\n",
    "ff.close()\n",
    "print(real_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an HTML table for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "85\n",
      "85\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Paper</th><th>Stopwords</th><th>Parts of speech</th><th>Real</th></tr><tr><td>1</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>2</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Jay</td></tr><tr><td>3</td><td style=\"color: red;\">Hamilton</td><td style=\"color: red;\">Hamilton</td><td>Jay</td></tr><tr><td>4</td><td style=\"color: red;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Jay</td></tr><tr><td>5</td><td style=\"color: red;\">Hamilton</td><td style=\"color: red;\">Hamilton</td><td>Jay</td></tr><tr><td>6</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>7</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>8</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>9</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>10</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>11</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>12</td><td style=\"color: red;\">Jay</td><td style=\"color: red;\">Jay</td><td>Hamilton</td></tr><tr><td>13</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>14</td><td style=\"color: red;\">Hamilton</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>15</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>16</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>17</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>18</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton and Madison</td></tr><tr><td>19</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton and Madison</td></tr><tr><td>20</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton and Madison</td></tr><tr><td>21</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>22</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>23</td><td style=\"color: red;\">Jay</td><td style=\"color: red;\">Jay</td><td>Hamilton</td></tr><tr><td>24</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>25</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>26</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>27</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>28</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>29</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>30</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>31</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>32</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>33</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>34</td><td style=\"color: red;\">Jay</td><td style=\"color: red;\">Jay</td><td>Hamilton</td></tr><tr><td>35</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>36</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>37</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>38</td><td style=\"color: green;\">Madison</td><td style=\"color: red;\">Hamilton</td><td>Madison</td></tr><tr><td>39</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>40</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>41</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>42</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>43</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>44</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>45</td><td style=\"color: red;\">Jay</td><td style=\"color: red;\">Jay</td><td>Madison</td></tr><tr><td>46</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>47</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>48</td><td style=\"color: green;\">Madison</td><td style=\"color: green;\">Madison</td><td>Madison</td></tr><tr><td>49</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Madison</td><td>Hamilton or Madison</td></tr><tr><td>50</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton or Madison</td></tr><tr><td>51</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton or Madison</td></tr><tr><td>52</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Madison</td><td>Hamilton or Madison</td></tr><tr><td>53</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Madison</td><td>Hamilton or Madison</td></tr><tr><td>54</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Madison</td><td>Hamilton or Madison</td></tr><tr><td>55</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton or Madison</td></tr><tr><td>56</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Madison</td><td>Hamilton or Madison</td></tr><tr><td>57</td><td style=\"color: orange;\">Hamilton</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton or Madison</td></tr><tr><td>58</td><td style=\"color: red;\">Hamilton</td><td style=\"color: red;\">Hamilton</td><td>Madison</td></tr><tr><td>59</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>60</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>61</td><td style=\"color: red;\">Jay</td><td style=\"color: red;\">Jay</td><td>Hamilton</td></tr><tr><td>62</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton or Madison</td></tr><tr><td>63</td><td style=\"color: orange;\">Madison</td><td style=\"color: orange;\">Hamilton</td><td>Hamilton or Madison</td></tr><tr><td>64</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Hamilton</td><td>Jay</td></tr><tr><td>65</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>66</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>67</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>68</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>69</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>70</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>71</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>72</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>73</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>74</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>75</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>76</td><td style=\"color: red;\">Madison</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>77</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>78</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>79</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>80</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>81</td><td style=\"color: red;\">Madison</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr><tr><td>82</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>83</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>84</td><td style=\"color: green;\">Hamilton</td><td style=\"color: green;\">Hamilton</td><td>Hamilton</td></tr><tr><td>85</td><td style=\"color: green;\">Hamilton</td><td style=\"color: red;\">Madison</td><td>Hamilton</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "stopword_authors = assign_author(stopword_result)\n",
    "pos_authors = assign_author(pos_result)\n",
    "\n",
    "def colorcode(assigned, real):\n",
    "    cellcolor = 'red'\n",
    "    if assigned == real:\n",
    "        cellcolor = 'green'\n",
    "    elif real.find(assigned) > -1:\n",
    "        cellcolor = 'orange'\n",
    "    return cellcolor\n",
    "\n",
    "print(len(stopword_authors))\n",
    "print(len(pos_authors))\n",
    "print(len(real_author))\n",
    "    \n",
    "answer_table = '<table><tr><th>Paper</th><th>Stopwords</th><th>Parts of speech</th><th>Real</th></tr>'\n",
    "for i in range(len(real_author)):\n",
    "    ra = real_author[i]\n",
    "    sa = stopword_authors[i]\n",
    "    pa = pos_authors[i]\n",
    "    answer_table += '<tr><td>%d</td>' % (i+1)     # Print the letter number\n",
    "    answer_table += '<td style=\"color: %s;\">%s</td>' % (colorcode(sa, ra), sa)\n",
    "    answer_table += '<td style=\"color: %s;\">%s</td>' % (colorcode(pa, ra), pa)\n",
    "    answer_table += '<td>%s</td></tr>' % ra\n",
    "answer_table += '</table>'\n",
    "\n",
    "HTML(answer_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...As you can see, the method is not perfect. 😄 A better method for the Federalist Papers problem would be to use a *trained* corpus, to let the model take into account what we know about the papers' authorship. \n",
    "\n",
    "Probably the most commonly-used method for authorship attribution today is known as Burrows' Delta, named after John Burrows who came up with it. The Delta algorithms are available in [a statistical package](https://sites.google.com/site/computationalstylistics/) called `stylo`, written for the R programming language for statistical computing. If this is something you anticipate wanting to use, that is a very good place to start."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
